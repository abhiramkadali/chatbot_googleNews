{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRP FAQ chatbot using pretrained Word2Vec Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re, unicodedata\n",
    "import string\n",
    "import pickle\n",
    "from nltk import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:/Users/akadali/Desktop/Deep_NLP/MLG_Capstone_ChatBot/ChatBot_GoogleW2V')\n",
    "data = pd.read_csv('trp_faq_dataset.csv', encoding = 'latin1')\n",
    "data = data[['question', 'answer']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing stop words, WordNetLemmatizer and punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~’'`\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "stops = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "import string\n",
    "puncs = string.punctuation\n",
    "#Adding additional punctuations\n",
    "puncs = puncs + \"’'`\" \n",
    "print(puncs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning\n",
    "-----\n",
    "\n",
    "* This dataset has a lot of contractions, hence all of them need to be removed/replaced within the dataset. The below function replaces the contractions with corresponding word pairs.\n",
    "\n",
    "* Also, there are quite a few abbreviations such as U.S., US, USI to be substituted with their expanded forms\n",
    "\n",
    "* removing additional spaces, if there are any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def text_clean(text):\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub('[%s]'%re.escape(puncs), ' ', text)\n",
    "    #convert u.s or us  to 'United States'\n",
    "    text = re.sub(r\" U.S. \", \" united states \", text)\n",
    "    text = re.sub(r\" US \", \" united states \", text)\n",
    "    text = re.sub(r\" USI \", \" united states india \", text)\n",
    "    text = re.sub(r\" +\",\" \", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing and Cleaning(2)\n",
    "----------------------------\n",
    "* Tokenizing the words\n",
    "* Lemmatization\n",
    "* removing numeric digits and punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocess(text):\n",
    "    #tokenizing\n",
    "    tokens = word_tokenize(text)\n",
    "    #converting to lower case and lemmatization\n",
    "    tokens = [lemmatizer.lemmatize(word.lower()) for word in tokens if word.lower() not in stops]\n",
    "    filtered_tokens = []\n",
    "    #Remove anything but alphabets - numbers, punctuations etc\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    #return list of lists for embedding vectors\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying 'Cleaning' and 'Preprocessing' methods on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean the questions dataset\n",
    "data['question'] = data['question'].apply(lambda x:text_clean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess the questions\n",
    "data['question'] = data['question'].apply(lambda x:text_preprocess(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-trained word and phrase vectors from gensim models\n",
    "-----------------------------------------\n",
    "* Getting GoogleNews-vectors-negative - A Pre-trained word and phrase vectors. 'Questions'in our dataset are converted to vectors by averaging the vectors of individual words in each question.\n",
    "\n",
    "* This can be loaded using 'gensim.models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.models\n",
    "#Changing the directory to get to the embeddings \n",
    "os.chdir('C:/Users/akadali/Desktop/Deep_NLP/MLG_Capstone_ChatBot/ChatBot_GoogleW2V/Word Embeddings')\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin',binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below function creates the 300-dimension vectors for each question (for all tokens that are present in the Google New pre-trained Word2Vec models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a feature vector by averaging embeddings for all words in a sentence\n",
    "def embedding_feats(list_of_tokens):\n",
    "    DIMENSION = 300\n",
    "    zero_vector = np.zeros(DIMENSION)\n",
    "    #feats = []\n",
    "    feat_for_this = zero_vector\n",
    "    count_for_this = 0\n",
    "    for token in list_of_tokens:\n",
    "        if token in model:\n",
    "            feat_for_this += model[token]\n",
    "            count_for_this+= 1\n",
    "    feats = feat_for_this/count_for_this\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating vectors for all questions in the faq dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.seterr(divide='ignore', invalid='ignore')\n",
    "question_vectors = [embedding_feats(x) for x in data['question']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This block of code would convert the user's question to a 300 dimensional vector and calculates the cosine_similarity against all question vectors in the FAQ dataset. \n",
    "* Obtains the correspoding answer of the best matched question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def get_response(query, t):\n",
    "    query = text_clean(query)\n",
    "    query = text_preprocess(query)\n",
    "    #print(query)\n",
    "    if len(query) == 0:\n",
    "        response = \"Can you please provide more information for me to undersatnd\"\n",
    "    else:\n",
    "        q_vec = [embedding_feats(query)]\n",
    "        sims = cosine_similarity(q_vec, question_vectors)\n",
    "        max_s = sims.max()\n",
    "        if max_s < t:\n",
    "            response = \"Hmm..sorry, I don't quite understand that, can you please rephrase your question\"\n",
    "        else:\n",
    "            max_i = np.argmax(sims)\n",
    "            response = data.answer[max_i]\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat():\n",
    "    print(\"Specify the confidence level\")\n",
    "    level = input(\"Confidence:\")\n",
    "    conf = int(level)/100\n",
    "    print(\"-------------------------------------------------\")\n",
    "    print(\"Start chatting with the bot (type 'quit' to stop)\")\n",
    "    print(\"-------------------------------------------------\")\n",
    "    print(\"Hi There....I'm Talent Referral Bot and I'm here to help you with referral inquiries\\n\")\n",
    "    print(\"**tip: please enter \\n'status_' to check your referral status \\n 'bonus_' to check your bonus payout status and \\n 'prog' for program related inquiry\")\n",
    "    while True:\n",
    "        user_input = input(\"You:\")\n",
    "        if user_input == 'status_':\n",
    "            print(\"can you please provide your referral details in the below order to check in database\\n1.Referral Name\\n2.Referral Email address\\n3.Your email address\")\n",
    "        elif user_input == 'bonus_':\n",
    "            print(\"can you please provide your referral details in the below order to check in database\\n1.Referral Name\\n2.Referral Email address\\n3.Your email address\")\n",
    "        #elif user_input == '':\n",
    "        #    print(\"Hmm..sorry, I don't quite understand that, can you please rephrase your question\")\n",
    "        elif (user_input).lower() == 'quit':\n",
    "            break            \n",
    "        response = get_response(user_input, conf)\n",
    "        print(\"Bot:\",response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specify the confidence level\n",
      "Confidence:80\n",
      "-------------------------------------------------\n",
      "Start chatting with the bot (type 'quit' to stop)\n",
      "-------------------------------------------------\n",
      "Hi There....I'm Talent Referral Bot and I'm here to help you with referral inquiries\n",
      "\n",
      "**tip: please enter 'status_' to check your referral status \n",
      " 'bonus_' to check your bonus payout status and \n",
      " 'prog' for program related inquiry\n",
      "You:bonus_\n",
      "can you please provide your referral details in the below order to check in database\n",
      "1.Referral Name\n",
      "2.Referral Email address\n",
      "3.Your email address\n",
      "Bot: Hmm..sorry, I don't quite understand that, can you please rephrase your question\n",
      "You:QUIT\n"
     ]
    }
   ],
   "source": [
    "chat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Chatbot GUI using tkinter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating GUI with tkinter\n",
    "import tkinter\n",
    "from tkinter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send():\n",
    "    msg = EntryBox.get(\"1.0\",'end-1c')\n",
    "    EntryBox.delete(\"0.0\",END)\n",
    "    if msg != '':\n",
    "        ChatLog.config(state=NORMAL)\n",
    "        ChatLog.insert(END, \"You: \" + msg + '\\n\\n')\n",
    "        ChatLog.config(foreground=\"#000000\", font=(\"Calibri\", 10 ))\n",
    "        res = get_response(msg, 0.8)\n",
    "        ChatLog.insert(END, \"Bot: \" + res + '\\n\\n')\n",
    "        ChatLog.config(state=DISABLED)\n",
    "        ChatLog.yview(END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base = Tk()\n",
    "base.title(\"Talent Referral BOT\")\n",
    "base.geometry(\"400x500\")\n",
    "base.resizable(width = TRUE, height = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Chat window\n",
    "ChatLog = Text(base, bd=0, bg=\"white\", height=\"8\", width=\"50\", font= (\"Calibri\", 10) ,fg='#000000')\n",
    "ChatLog.config(state=DISABLED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bind scrollbar to Chat window\n",
    "scrollbar = Scrollbar(base, command=ChatLog.yview, cursor=\"heart\")\n",
    "ChatLog['yscrollcommand'] = scrollbar.set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Button to send message\n",
    "SendButton = Button(base, font=(\"Calibri\",12,'bold'), text=\"Send\", width=\"12\", height=5,\n",
    "                    bd=0, bg=\"#86bc25\", activebackground=\"#3c9d9b\",fg='#ffffff',\n",
    "                    command = send)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the box to enter message\n",
    "EntryBox = Text(base, bd=0, bg=\"white\",width=\"29\", height=\"5\", font=\"Calibri\")\n",
    "#EntryBox.bind(\"<Return>\", send)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Place all components on the screen\n",
    "scrollbar.place(x=376,y=6, height=386)\n",
    "ChatLog.place(x=6,y=6, height=386, width=370)\n",
    "EntryBox.place(x=128, y=401, height=90, width=265)\n",
    "SendButton.place(x=6, y=401, height=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
